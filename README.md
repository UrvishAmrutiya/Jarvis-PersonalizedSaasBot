# ğŸ¤– Jarvis-PersonalizedSaasBot  
*Self-Hosted RAG Assistant Powered by Llama + Pinecone + Next.js*

Jarvis-PersonalizedSaasBot is a **private AI documentation assistant** that instantly answers questions about a SaaS product's features, pricing, security, and how-to guidance â€” grounded in real internal documentation with source citations.

This is a **fully self-hosted enterprise AI copilot**, ensuring **data stays private** with no external cloud usage.

---

## âœ¨ Key Features

- ğŸ” **Self-Hosted LLM** using LM Studio (Llama-3.2-3B-Instruct)
- ğŸ§  **RAG Retrieval** using Pinecone for accurate context matching
- ğŸ“š **Answers with citations** â†’ audit-ready & trusted
- ğŸ¨ **Cinematic UI** built in Next.js + Framer Motion
- ğŸ’¬ **Real-time chat** with typing animation + online status indicator
- ğŸ”„ **Start new session** any time
- ğŸ“„ **Download chat** as `.txt` transcript
- ğŸš¦ **Backend & model health monitoring**
- ğŸ§© **Modular architecture** â†’ easy to extend

---

## ğŸ— Architecture

```mermaid
flowchart TD
    A([âœ¨ Next.js Frontend]) --> B([ğŸ§  Node.js RAG Backend])
    B --> C([ğŸ” Pinecone Vector Database])
    B --> D([ğŸ¤– Llama Model via LM Studio])
```

---

## ğŸ“‚ Project Structure

```
Jarvis-PersonalizedSaasBot/
â”œâ”€â”€ frontend/         # Next.js UI
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ public/
â””â”€â”€ backend/          # Chat + RAG Engine (Node.js)
    â”œâ”€â”€ server.js
    â”œâ”€â”€ .env
    â””â”€â”€ package.json
```

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Backend Setup

```bash
cd backend
npm install
```

Create a `.env` file in the `backend/` directory:

```env
LMSTUDIO_BASE_URL=http://localhost:1234/v1
PINECONE_API_KEY=your_key_here
PINECONE_INDEX=jarvis-knowledge
PINECONE_REGION=us-east-1
PORT=8000
```

Start the backend server:

```bash
node server.js
```

### 2ï¸âƒ£ Frontend Setup

```bash
cd ../frontend
npm install
npm run dev
```

The app will be available at `http://localhost:3000`

---

## ğŸ’¡ How It Works

1. **User asks a question** via the chat interface
2. **Backend retrieves relevant context** from Pinecone vector database
3. **Sends query + context** to Llama running in LM Studio
4. **Gets grounded response** with proper citations
5. **UI displays answer** + sources + token stats
6. **Transcript downloadable** for compliance & review

---

## ğŸ§ª Try These Demo Prompts

- What does this SaaS product do?
- How do users track tasks?
- Compare Business vs Enterprise plan
- Tell me more about SOC2 compliance
- What security certifications do you have?
- How do I integrate with my existing tools?
- Download transcript

---

## ğŸ›¡ Security Highlights

- ğŸš« **No cloud inference** â†’ zero data leakage
- ğŸ”’ **Fully self-hosted deployments**
- ğŸ“ **Works even in offline environments** (except Pinecone)
- ğŸ¢ **Enterprise-compliant setup**
- ğŸ” **Private data never leaves your infrastructure**

---

## ğŸ“¸ Demo Video & Screenshots

### ğŸ¥ Video Demonstration

See Jarvis in action:

ğŸ‘‰ [**Watch Demo Video**](https://drive.google.com/file/d/1s3eSjGxs9JiNGOJbZBpLQ0cO5jXXGeKB/view?usp=sharing)

### ğŸ“¸ UI Preview

#### ğŸ”¹ Landing Page (Jarvis Reactor Animation)

![Landing Page](https://drive.google.com/uc?export=view&id=1ols-jDHdqNezb8xI_e0P-5XMsfMacQuk)

#### ğŸ”¹ Chat Screen (Citations + RAG Retrieval)

![Chat UI](https://drive.google.com/uc?export=view&id=12HLBf-RGyzKdpgivQHbR6k2uuOqq7MNC)

## ğŸ›  Tech Stack

| Component | Technology |
|-----------|-----------|
| **Frontend** | Next.js 14, React, Tailwind CSS, Framer Motion |
| **Backend** | Node.js, Express |
| **LLM** | Llama 3.2 (3B Instruct) via LM Studio |
| **Vector DB** | Pinecone |
| **Deployment** | Self-hosted (Docker-ready) |

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
